{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import text_processors\n",
    "from progressbar import ProgressBar\n",
    "import data_grab\n",
    "\n",
    "import pymc3 as pm \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contest_metric(numpy_array_predictions, numpy_array_actual_values):\n",
    "    return metrics.weighted_rmsle(numpy_array_predictions, numpy_array_actual_values,\n",
    "            weights=metrics.KEEPING_IT_CLEAN_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contest_scoring(X, y, pipeline):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    s1 = pipeline.fit(X_train, y_train['score_lvl_1']).predict(X_test)\n",
    "    s2 = pipeline.fit(X_train, y_train['score_lvl_2']).predict(X_test)\n",
    "    s3 = pipeline.fit(X_train, y_train['score_lvl_3']).predict(X_test)\n",
    "    results = np.dstack((s1, s2, s3))\n",
    "    score = contest_metric(np.round(results[0]), np.array(y_test))\n",
    "    print(\"Contest score of {}\".format(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_model(X, y, pipeline):\n",
    "    scores = cross_val_score(pipeline, X, y, cv=3, n_jobs=1, verbose=1)\n",
    "    mean_score = np.mean(scores)\n",
    "    std_dev_score = np.std(scores)\n",
    "    print(\"CV score of {} +/- {}\".format(mean_score, std_dev_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    features = df.drop(['score_lvl_1', 'score_lvl_2', 'score_lvl_3'], axis=1)\n",
    "    response = df[['score_lvl_1', 'score_lvl_2', 'score_lvl_3']].astype(np.float64)  #for numerical progression\n",
    "    # response = df[['score_lvl_1', 'score_lvl_2', 'score_lvl_3']].astype(np.int8)  # for categorical response\n",
    "    return features, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('pickle_jar/review_text_sentiment_hierarchical_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.previous_inspection_delta = df.previous_inspection_delta.fillna(0)\n",
    "df.previous_inspection_delta = df.previous_inspection_delta.dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # time delta bins\n",
    "# tdmax = df.review_delta.max()\n",
    "# tdmin = df.review_delta.min()\n",
    "# df['review_delta_bin'] = pd.cut(df[\"review_delta\"], np.arange(tdmin, tdmax, 30))\n",
    "# tdmax = df.previous_inspection_delta.max()\n",
    "# tdmin = df.previous_inspection_delta.min()\n",
    "# df['previous_inspection_delta_bin'] = pd.cut(df[\"previous_inspection_delta\"], np.arange(tdmin, tdmax, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = ['score_lvl_1', 'score_lvl_2', 'score_lvl_3']\n",
    "# model_features = ['review_delta', 'previous_inspection_delta', 'polarity', 'subjectivity', 'neg', 'pos', 'neu', 'compound']\n",
    "model_features = ['review_delta', 'polarity', 'subjectivity', 'neg', 'pos', 'neu', 'compound']\n",
    "X, y = extract_features(df[model_features + scores].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4071065, 140)\n",
      "(1925254, 7)\n",
      "(1925254, 3)\n"
     ]
    }
   ],
   "source": [
    "print df.shape\n",
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_lvl_1\n",
      "CV score of 1.0 +/- 0.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score_lvl_2\n",
      "CV score of 1.0 +/- 0.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score_lvl_3\n",
      "CV score of 1.0 +/- 0.0\n",
      "\n",
      "Contest score of 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# set classifiers to test\n",
    "# estimator = LinearRegression()\n",
    "estimator = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "# estimator = SGDClassifier(n_jobs=-1, random_state=42)\n",
    "# estimator = BaggingClassifier(random_state=42)\n",
    "\n",
    "# can use with text if convert X to dense with .toarray() but is super heavy on ram\n",
    "pipeline = Pipeline([\n",
    "        ('normalizer', Normalizer()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', estimator),\n",
    "])\n",
    "\n",
    "for score in scores:\n",
    "    print(score)\n",
    "    score_model(X, y[score], pipeline)\n",
    "\n",
    "print\n",
    "contest_scoring(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>score_lvl_1</td>   <th>  R-squared:         </th>  <td>   0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   93.56</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 Jul 2015</td> <th>  Prob (F-statistic):</th>  <td>3.76e-137</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:23:38</td>     <th>  Log-Likelihood:    </th> <td>-5.7534e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>1925254</td>     <th>  AIC:               </th>  <td>1.151e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>1925246</td>     <th>  BIC:               </th>  <td>1.151e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>    3.4146</td> <td>    0.449</td> <td>    7.600</td> <td> 0.000</td> <td>    2.534     4.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>review_delta</th> <td>    0.0001</td> <td>  5.1e-06</td> <td>   23.013</td> <td> 0.000</td> <td>    0.000     0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>polarity</th>     <td>   -0.0344</td> <td>    0.022</td> <td>   -1.538</td> <td> 0.124</td> <td>   -0.078     0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>subjectivity</th> <td>    0.0540</td> <td>    0.025</td> <td>    2.168</td> <td> 0.030</td> <td>    0.005     0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>neg</th>          <td>    0.9708</td> <td>    0.455</td> <td>    2.132</td> <td> 0.033</td> <td>    0.079     1.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos</th>          <td>    0.8400</td> <td>    0.451</td> <td>    1.862</td> <td> 0.063</td> <td>   -0.044     1.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>neu</th>          <td>    0.8203</td> <td>    0.450</td> <td>    1.825</td> <td> 0.068</td> <td>   -0.061     1.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>compound</th>     <td>   -0.0675</td> <td>    0.009</td> <td>   -7.234</td> <td> 0.000</td> <td>   -0.086    -0.049</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1115658.461</td> <th>  Durbin-Watson:     </th>   <td>   0.017</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>    <th>  Jarque-Bera (JB):  </th> <td>13477102.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 2.589</td>    <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>14.882</td>    <th>  Cond. No.          </th>   <td>2.94e+05</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            score_lvl_1   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                  0.000\n",
       "Method:                 Least Squares   F-statistic:                     93.56\n",
       "Date:                Sat, 11 Jul 2015   Prob (F-statistic):          3.76e-137\n",
       "Time:                        13:23:38   Log-Likelihood:            -5.7534e+06\n",
       "No. Observations:             1925254   AIC:                         1.151e+07\n",
       "Df Residuals:                 1925246   BIC:                         1.151e+07\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept        3.4146      0.449      7.600      0.000         2.534     4.295\n",
       "review_delta     0.0001    5.1e-06     23.013      0.000         0.000     0.000\n",
       "polarity        -0.0344      0.022     -1.538      0.124        -0.078     0.009\n",
       "subjectivity     0.0540      0.025      2.168      0.030         0.005     0.103\n",
       "neg              0.9708      0.455      2.132      0.033         0.079     1.863\n",
       "pos              0.8400      0.451      1.862      0.063        -0.044     1.724\n",
       "neu              0.8203      0.450      1.825      0.068        -0.061     1.701\n",
       "compound        -0.0675      0.009     -7.234      0.000        -0.086    -0.049\n",
       "==============================================================================\n",
       "Omnibus:                  1115658.461   Durbin-Watson:                   0.017\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         13477102.476\n",
       "Skew:                           2.589   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.882   Cond. No.                     2.94e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.94e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "model = smf.ols(formula='score_lvl_1 ~'+'+'.join(model_features), data=df[model_features + scores].dropna()).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>review_delta</th>\n",
       "      <td>19206.698621</td>\n",
       "      <td>1</td>\n",
       "      <td>841.975840</td>\n",
       "      <td>4.433674e-185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous_inspection_delta</th>\n",
       "      <td>463551.215022</td>\n",
       "      <td>1</td>\n",
       "      <td>20320.979218</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity</th>\n",
       "      <td>11.553256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506467</td>\n",
       "      <td>4.766723e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity</th>\n",
       "      <td>32.118953</td>\n",
       "      <td>1</td>\n",
       "      <td>1.408018</td>\n",
       "      <td>2.353858e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>90.939919</td>\n",
       "      <td>1</td>\n",
       "      <td>3.986589</td>\n",
       "      <td>4.586396e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>62.607017</td>\n",
       "      <td>1</td>\n",
       "      <td>2.744542</td>\n",
       "      <td>9.758718e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu</th>\n",
       "      <td>58.170630</td>\n",
       "      <td>1</td>\n",
       "      <td>2.550062</td>\n",
       "      <td>1.102901e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>1005.620308</td>\n",
       "      <td>1</td>\n",
       "      <td>44.083995</td>\n",
       "      <td>3.146670e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>43210335.339146</td>\n",
       "      <td>1894238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sum_sq       df             F  \\\n",
       "review_delta                  19206.698621        1    841.975840   \n",
       "previous_inspection_delta    463551.215022        1  20320.979218   \n",
       "polarity                         11.553256        1      0.506467   \n",
       "subjectivity                     32.118953        1      1.408018   \n",
       "neg                              90.939919        1      3.986589   \n",
       "pos                              62.607017        1      2.744542   \n",
       "neu                              58.170630        1      2.550062   \n",
       "compound                       1005.620308        1     44.083995   \n",
       "Residual                   43210335.339146  1894238           NaN   \n",
       "\n",
       "                                  PR(>F)  \n",
       "review_delta               4.433674e-185  \n",
       "previous_inspection_delta   0.000000e+00  \n",
       "polarity                    4.766723e-01  \n",
       "subjectivity                2.353858e-01  \n",
       "neg                         4.586396e-02  \n",
       "pos                         9.758718e-02  \n",
       "neu                         1.102901e-01  \n",
       "compound                    3.146670e-11  \n",
       "Residual                             NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "sm.stats.anova_lm(model, typ=2) # Type 2 ANOVA DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept      -3.550546\n",
      "review_delta    0.000927\n",
      "polarity        0.294398\n",
      "subjectivity   -0.430076\n",
      "neg             8.069998\n",
      "pos             8.031545\n",
      "neu             7.440557\n",
      "compound       -0.328166\n",
      "dtype: float64\n",
      "Group effect test [[ 242.21228155]]\n",
      "Covariate effect test [[ 7.02122616]]\n"
     ]
    }
   ],
   "source": [
    "print model.params\n",
    "A=np.identity(len(model.params)) # identity matrix with size = number of params\n",
    "GroupTest=A[1:3,:] # for the categorical var., keep the corresponding rows of A\n",
    "CovTest=A[3,:] # row for the continuous var.\n",
    "print \"Group effect test\",model.f_test(GroupTest).fvalue\n",
    "print \"Covariate effect test\",model.f_test(CovTest).fvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_lvl_1</th>\n",
       "      <th>score_lvl_2</th>\n",
       "      <th>score_lvl_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2848354</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848355</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848356</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score_lvl_1  score_lvl_2  score_lvl_3\n",
       "2848354            0            0            0\n",
       "2848355            0            0            0\n",
       "2848356            0            0            0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f89ec145deee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Expected value of outcome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Likelihood (sampling distribution) of observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X1' is not defined"
     ]
    }
   ],
   "source": [
    "from pymc3 import Model, Normal, HalfNormal\n",
    "basic_model = Model()\n",
    "\n",
    "with basic_model:\n",
    "\n",
    "    # Priors for unknown model parameters\n",
    "    alpha = Normal('alpha', mu=0, sd=10)\n",
    "    beta = Normal('beta', mu=0, sd=10, shape=2)\n",
    "    sigma = HalfNormal('sigma', sd=1)\n",
    "\n",
    "    # Expected value of outcome\n",
    "    mu = alpha + beta[0]*X.review_delta + beta[1]*X.polarity\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y_obs = Normal('Y_obs', mu=mu, sd=sigma, observed=Y.score_lvl_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
