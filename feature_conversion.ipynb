{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import text_processors\n",
    "from progressbar import ProgressBar\n",
    "import data_grab\n",
    "from time import time\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.externals import joblib\n",
    "from scipy.sparse import csr_matrix, hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contest_metric(numpy_array_predictions, numpy_array_actual_values):\n",
    "    return metrics.weighted_rmsle(numpy_array_predictions, numpy_array_actual_values,\n",
    "            weights=metrics.KEEPING_IT_CLEAN_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contest_scoring(X, y, pipeline):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    s1 = pipeline.fit(X_train, y_train['score_lvl_1']).predict(X_test)\n",
    "    s2 = pipeline.fit(X_train, y_train['score_lvl_2']).predict(X_test)\n",
    "    s3 = pipeline.fit(X_train, y_train['score_lvl_3']).predict(X_test)\n",
    "    results = np.dstack((s1, s2, s3))\n",
    "    score = contest_metric(np.round(results[0]), np.array(y_test))\n",
    "    print(\"Contest score of {}\".format(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def raw_scoring(p1, p2, p3, ytrue):\n",
    "    '''since cross_val_score doesn't allow you to round the results beforehand. also for pymc3 and other non-sklearn models'''\n",
    "    score1 = accuracy_score(ytrue['score_lvl_1'], np.round(p1))\n",
    "    print(\"Level 1 accuracy score of {}\".format(score1))\n",
    "    score2 = accuracy_score(ytrue['score_lvl_2'], np.round(p2))\n",
    "    print(\"Level 2 accuracy score of {}\".format(score2))\n",
    "    score3 = accuracy_score(ytrue['score_lvl_3'], np.round(p3))\n",
    "    print(\"Level 3 accuracy score of {}\".format(score3))\n",
    "    \n",
    "    results = np.dstack((p1, p2, p3))[0]\n",
    "    score = contest_metric(np.round(results), np.array(ytrue))\n",
    "    print(\"Contest score of {}\".format(score))\n",
    "    \n",
    "    rounded = np.clip(np.round(results), 0, np.inf)\n",
    "    compare = pd.concat([pd.DataFrame(np.concatenate((results, rounded), axis=1)), ytrue.reset_index(drop=True)], axis=1)\n",
    "    compare.columns = ['pred1','pred2','pred3','round1','round2','round3','true1','true2','true3']\n",
    "    compare['offset1'] = compare.round1-compare.true1\n",
    "    compare['offset2'] = compare.round2-compare.true2\n",
    "    compare['offset3'] = compare.round3-compare.true3\n",
    "        \n",
    "    return score1, score2, score3, score, compare.head(10)\n",
    "\n",
    "    \n",
    "def raw_fit(X, y, pipeline):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, random_state=42)\n",
    "    \n",
    "    p1 = pipeline.fit(xtrain, ytrain['score_lvl_1']).predict(xtest)\n",
    "    p2 = pipeline.fit(xtrain, ytrain['score_lvl_2']).predict(xtest)\n",
    "    p3 = pipeline.fit(xtrain, ytrain['score_lvl_3']).predict(xtest)\n",
    "        \n",
    "    return p1, p2, p3, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    features = df.drop(['score_lvl_1', 'score_lvl_2', 'score_lvl_3'], axis=1)\n",
    "    response = df[['score_lvl_1', 'score_lvl_2', 'score_lvl_3']].astype(np.int8)\n",
    "    \n",
    "    return features, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('pickle_jar/review_text_sentiment_hierarchical_df')\n",
    "# prep = pd.read_pickle('pickle_jar/preprocessed_review_text_hierarchical_df')\n",
    "# df = pd.concat([df, prep.preprocessed_review_text], axis=1)\n",
    "sim = pd.read_pickle('pickle_jar/similarity_vectors_df')\n",
    "# tfidf = joblib.load('pickle_jar/tfidf_preprocessed_ngram3_sublinear_1mil_hierarchical_dropna')\n",
    "# matrix = joblib.load('pickle_jar/similarity_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.previous_inspection_delta = df.previous_inspection_delta.fillna(0)\n",
    "df.previous_inspection_delta = df.previous_inspection_delta.dt.days.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (53 of 53) |#########################| Elapsed Time: 0:03:42 Time: 0:03:42\n"
     ]
    }
   ],
   "source": [
    "def get_out(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "\n",
    "topics = ['manager', 'supervisor', 'training', 'safety', 'disease', 'ill', 'sick', 'poisoning', 'hygiene', 'raw', 'undercooked', 'cold', 'clean', 'sanitary', 'wash', 'jaundice', 'yellow', 'hazard', 'inspection', 'violation', 'gloves', 'hairnet', 'nails', 'jewelry', 'sneeze', 'cough', 'runny', 'illegal', 'rotten', 'dirty', 'mouse', 'cockroach', 'contaminated', 'gross', 'disgusting', 'stink', 'old', 'parasite', 'reheat', 'frozen', 'broken', 'drip', 'bathroom', 'toilet', 'leak', 'trash', 'dark', 'lights', 'dust', 'puddle', 'pesticide', 'bugs', 'mold', ]\n",
    "pbar = ProgressBar(maxval=len(topics)).start()\n",
    "for index, i in enumerate(topics):\n",
    "    sim[i] = sim[i].apply(get_out)\n",
    "    pbar.update(index)\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df,sim[topics]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = data_grab.get_selects('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped = df.dropna(subset=['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped['user_yelping_since_delta'] = (dropped.review_date - dropped.user_yelping_since).astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped['user_most_recent_elite_year_delta'] = (dropped.review_date.dt.year - dropped.user_most_recent_elite_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped['restaurant_categories'] = train.restaurant_categories.apply(lambda x: sorted(x))\n",
    "dropped['restaurant_neighborhoods'] = train.restaurant_neighborhoods.apply(lambda x: sorted(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped.drop(['review_text', 'review_date', 'user_id', 'restaurant_full_address', 'restaurant_name',\n",
    "         'inspection_date', 'inspection_id', 'inspection_date', 'sentiment', 'vader'], axis=1, inplace=True)\n",
    "dropped.drop(['restaurant_neighborhood_1',\n",
    " 'restaurant_neighborhood_2',\n",
    " 'restaurant_neighborhood_3',\n",
    " 'restaurant_category_1',\n",
    " 'restaurant_category_2',\n",
    " 'restaurant_category_3',\n",
    " 'restaurant_category_4',\n",
    " 'restaurant_category_5',\n",
    " 'restaurant_category_6',\n",
    " 'restaurant_category_7',], axis=1, inplace=True)\n",
    "dropped.drop(['user_yelping_since', 'restaurant_attributes_by_appointment_only', 'restaurant_open', 'user_most_recent_elite_year'] , axis=1, inplace=True)\n",
    "dropped.drop(['review_year',\n",
    " 'review_month',\n",
    " 'review_day',\n",
    " 'review_dayofweek',\n",
    " 'review_quarter',\n",
    " 'review_dayofyear',\n",
    " 'inspection_dayofyear',], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped['review_stars'] = dropped.review_stars.fillna(0).astype('category')\n",
    "dropped[['user_compliments_cool', 'user_compliments_cute', 'user_compliments_funny', 'user_compliments_hot',\n",
    " 'user_compliments_list', 'user_compliments_more', 'user_compliments_note', 'user_compliments_photos', 'user_compliments_plain',\n",
    " 'user_compliments_profile', 'user_compliments_writer', 'checkin_counts']] = dropped[['user_compliments_cool', 'user_compliments_cute', 'user_compliments_funny', 'user_compliments_hot',\n",
    " 'user_compliments_list', 'user_compliments_more', 'user_compliments_note', 'user_compliments_photos', 'user_compliments_plain',\n",
    " 'user_compliments_profile', 'user_compliments_writer', 'checkin_counts']].fillna(0)\n",
    "dropped[['restaurant_attributes_ages_allowed',\n",
    "         'restaurant_attributes_alcohol', \n",
    "         'restaurant_attributes_attire', \n",
    "         'restaurant_attributes_byob_corkage', \n",
    "         'restaurant_attributes_noise_level', \n",
    "         'restaurant_attributes_smoking', \n",
    "         'restaurant_attributes_wifi']] = dropped[['restaurant_attributes_ages_allowed',\n",
    "                                                   'restaurant_attributes_alcohol', \n",
    "                                                   'restaurant_attributes_attire', \n",
    "                                                   'restaurant_attributes_byob_corkage', \n",
    "                                                   'restaurant_attributes_noise_level', \n",
    "                                                   'restaurant_attributes_smoking', \n",
    "                                                   'restaurant_attributes_wifi']].convert_objects().fillna('nan')\n",
    "dropped[['restaurant_hours_friday_close',\n",
    " 'restaurant_hours_friday_open',\n",
    " 'restaurant_hours_monday_close',\n",
    " 'restaurant_hours_monday_open',\n",
    " 'restaurant_hours_saturday_close',\n",
    " 'restaurant_hours_saturday_open',\n",
    " 'restaurant_hours_sunday_close',\n",
    " 'restaurant_hours_sunday_open',\n",
    " 'restaurant_hours_thursday_close',\n",
    " 'restaurant_hours_thursday_open',\n",
    " 'restaurant_hours_tuesday_close',\n",
    " 'restaurant_hours_tuesday_open',\n",
    " 'restaurant_hours_wednesday_close',\n",
    " 'restaurant_hours_wednesday_open']] = dropped[[ 'restaurant_hours_friday_close',\n",
    " 'restaurant_hours_friday_open',\n",
    " 'restaurant_hours_monday_close',\n",
    " 'restaurant_hours_monday_open',\n",
    " 'restaurant_hours_saturday_close',\n",
    " 'restaurant_hours_saturday_open',\n",
    " 'restaurant_hours_sunday_close',\n",
    " 'restaurant_hours_sunday_open',\n",
    " 'restaurant_hours_thursday_close',\n",
    " 'restaurant_hours_thursday_open',\n",
    " 'restaurant_hours_tuesday_close',\n",
    " 'restaurant_hours_tuesday_open',\n",
    " 'restaurant_hours_wednesday_close',\n",
    " 'restaurant_hours_wednesday_open']].convert_objects().fillna('nan')\n",
    "dropped[['restaurant_ambience',\n",
    "         'restaurant_music',\n",
    "         'restaurant_parking',\n",
    "         'restaurant_zipcode']] = dropped[['restaurant_ambience',\n",
    "                                            'restaurant_music',\n",
    "                                            'restaurant_parking',\n",
    "                                            'restaurant_zipcode']].convert_objects().fillna('nan')\n",
    "dropped[['manager',\n",
    " 'supervisor',\n",
    " 'training',\n",
    " 'safety',\n",
    " 'disease',\n",
    " 'ill',\n",
    " 'sick',\n",
    " 'poisoning',\n",
    " 'hygiene',\n",
    " 'raw',\n",
    " 'undercooked',\n",
    " 'cold',\n",
    " 'clean',\n",
    " 'sanitary',\n",
    " 'wash',\n",
    " 'jaundice',\n",
    " 'yellow',\n",
    " 'hazard',\n",
    " 'inspection',\n",
    " 'violation',\n",
    " 'gloves',\n",
    " 'hairnet',\n",
    " 'nails',\n",
    " 'jewelry',\n",
    " 'sneeze',\n",
    " 'cough',\n",
    " 'runny',\n",
    " 'illegal',\n",
    " 'rotten',\n",
    " 'dirty',\n",
    " 'mouse',\n",
    " 'cockroach',\n",
    " 'contaminated',\n",
    " 'gross',\n",
    " 'disgusting',\n",
    " 'stink',\n",
    " 'old',\n",
    " 'parasite',\n",
    " 'reheat',\n",
    " 'frozen',\n",
    " 'broken',\n",
    " 'drip',\n",
    " 'bathroom',\n",
    " 'toilet',\n",
    " 'leak',\n",
    " 'trash',\n",
    " 'dark',\n",
    " 'lights',\n",
    " 'dust',\n",
    " 'puddle',\n",
    " 'pesticide',\n",
    " 'bugs',\n",
    " 'mold',]] = dropped[['manager',\n",
    " 'supervisor',\n",
    " 'training',\n",
    " 'safety',\n",
    " 'disease',\n",
    " 'ill',\n",
    " 'sick',\n",
    " 'poisoning',\n",
    " 'hygiene',\n",
    " 'raw',\n",
    " 'undercooked',\n",
    " 'cold',\n",
    " 'clean',\n",
    " 'sanitary',\n",
    " 'wash',\n",
    " 'jaundice',\n",
    " 'yellow',\n",
    " 'hazard',\n",
    " 'inspection',\n",
    " 'violation',\n",
    " 'gloves',\n",
    " 'hairnet',\n",
    " 'nails',\n",
    " 'jewelry',\n",
    " 'sneeze',\n",
    " 'cough',\n",
    " 'runny',\n",
    " 'illegal',\n",
    " 'rotten',\n",
    " 'dirty',\n",
    " 'mouse',\n",
    " 'cockroach',\n",
    " 'contaminated',\n",
    " 'gross',\n",
    " 'disgusting',\n",
    " 'stink',\n",
    " 'old',\n",
    " 'parasite',\n",
    " 'reheat',\n",
    " 'frozen',\n",
    " 'broken',\n",
    " 'drip',\n",
    " 'bathroom',\n",
    " 'toilet',\n",
    " 'leak',\n",
    " 'trash',\n",
    " 'dark',\n",
    " 'lights',\n",
    " 'dust',\n",
    " 'puddle',\n",
    " 'pesticide',\n",
    " 'bugs',\n",
    " 'mold',]].fillna(0)\n",
    "dropped.user_most_recent_elite_year_delta = dropped.user_most_recent_elite_year_delta.fillna(dropped.user_most_recent_elite_year_delta.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropped = dropped.dropna(subset=['restaurant_attributes_price_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dropped = pd.read_pickle('pickle_jar/final_dropped')\n",
    "# dropped.to_pickle('pickle_jar/final_dropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1924336, 167)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['restaurant_id',\n",
       " 'review_stars',\n",
       " 'review_votes_cool',\n",
       " 'review_votes_funny',\n",
       " 'review_votes_useful',\n",
       " 'user_average_stars',\n",
       " 'user_compliments_cool',\n",
       " 'user_compliments_cute',\n",
       " 'user_compliments_funny',\n",
       " 'user_compliments_hot',\n",
       " 'user_compliments_list',\n",
       " 'user_compliments_more',\n",
       " 'user_compliments_note',\n",
       " 'user_compliments_photos',\n",
       " 'user_compliments_plain',\n",
       " 'user_compliments_profile',\n",
       " 'user_compliments_writer',\n",
       " 'user_fans',\n",
       " 'user_name',\n",
       " 'user_review_count',\n",
       " 'user_votes_cool',\n",
       " 'user_votes_funny',\n",
       " 'user_votes_useful',\n",
       " 'restaurant_stars',\n",
       " 'restaurant_attributes_accepts_credit_cards',\n",
       " 'restaurant_attributes_ages_allowed',\n",
       " 'restaurant_attributes_alcohol',\n",
       " 'restaurant_attributes_attire',\n",
       " 'restaurant_attributes_byob',\n",
       " 'restaurant_attributes_byob_corkage',\n",
       " 'restaurant_attributes_caters',\n",
       " 'restaurant_attributes_coat_check',\n",
       " 'restaurant_attributes_corkage',\n",
       " 'restaurant_attributes_delivery',\n",
       " 'restaurant_attributes_dietary_restrictions_dairy_free',\n",
       " 'restaurant_attributes_dietary_restrictions_gluten_free',\n",
       " 'restaurant_attributes_dietary_restrictions_halal',\n",
       " 'restaurant_attributes_dietary_restrictions_kosher',\n",
       " 'restaurant_attributes_dietary_restrictions_soy_free',\n",
       " 'restaurant_attributes_dietary_restrictions_vegan',\n",
       " 'restaurant_attributes_dietary_restrictions_vegetarian',\n",
       " 'restaurant_attributes_dogs_allowed',\n",
       " 'restaurant_attributes_drive_thr',\n",
       " 'restaurant_attributes_good_for_dancing',\n",
       " 'restaurant_attributes_good_for_groups',\n",
       " 'restaurant_attributes_good_for_breakfast',\n",
       " 'restaurant_attributes_good_for_brunch',\n",
       " 'restaurant_attributes_good_for_dessert',\n",
       " 'restaurant_attributes_good_for_dinner',\n",
       " 'restaurant_attributes_good_for_latenight',\n",
       " 'restaurant_attributes_good_for_lunch',\n",
       " 'restaurant_attributes_good_for_kids',\n",
       " 'restaurant_attributes_happy_hour',\n",
       " 'restaurant_attributes_has_tv',\n",
       " 'restaurant_attributes_noise_level',\n",
       " 'restaurant_attributes_open_24_hours',\n",
       " 'restaurant_attributes_order_at_counter',\n",
       " 'restaurant_attributes_outdoor_seating',\n",
       " 'restaurant_attributes_payment_types_amex',\n",
       " 'restaurant_attributes_payment_types_cash_only',\n",
       " 'restaurant_attributes_payment_types_discover',\n",
       " 'restaurant_attributes_payment_types_mastercard',\n",
       " 'restaurant_attributes_payment_types_visa',\n",
       " 'restaurant_attributes_price_range',\n",
       " 'restaurant_attributes_smoking',\n",
       " 'restaurant_attributes_take_out',\n",
       " 'restaurant_attributes_takes_reservations',\n",
       " 'restaurant_attributes_waiter_service',\n",
       " 'restaurant_attributes_wheelchair_accessible',\n",
       " 'restaurant_attributes_wifi',\n",
       " 'restaurant_city',\n",
       " 'restaurant_hours_friday_close',\n",
       " 'restaurant_hours_friday_open',\n",
       " 'restaurant_hours_monday_close',\n",
       " 'restaurant_hours_monday_open',\n",
       " 'restaurant_hours_saturday_close',\n",
       " 'restaurant_hours_saturday_open',\n",
       " 'restaurant_hours_sunday_close',\n",
       " 'restaurant_hours_sunday_open',\n",
       " 'restaurant_hours_thursday_close',\n",
       " 'restaurant_hours_thursday_open',\n",
       " 'restaurant_hours_tuesday_close',\n",
       " 'restaurant_hours_tuesday_open',\n",
       " 'restaurant_hours_wednesday_close',\n",
       " 'restaurant_hours_wednesday_open',\n",
       " 'restaurant_latitude',\n",
       " 'restaurant_longitude',\n",
       " 'restaurant_review_count',\n",
       " 'checkin_counts',\n",
       " 'restaurant_ambience',\n",
       " 'restaurant_music',\n",
       " 'restaurant_parking',\n",
       " 'restaurant_street',\n",
       " 'restaurant_zipcode',\n",
       " 'score_lvl_1',\n",
       " 'score_lvl_2',\n",
       " 'score_lvl_3',\n",
       " 'review_delta',\n",
       " 'previous_inspection_delta',\n",
       " 'inspection_year',\n",
       " 'inspection_month',\n",
       " 'inspection_day',\n",
       " 'inspection_dayofweek',\n",
       " 'inspection_quarter',\n",
       " 'inspection_dayofyear',\n",
       " 'polarity',\n",
       " 'subjectivity',\n",
       " 'neg',\n",
       " 'neu',\n",
       " 'pos',\n",
       " 'compound',\n",
       " 'manager',\n",
       " 'supervisor',\n",
       " 'training',\n",
       " 'safety',\n",
       " 'disease',\n",
       " 'ill',\n",
       " 'sick',\n",
       " 'poisoning',\n",
       " 'hygiene',\n",
       " 'raw',\n",
       " 'undercooked',\n",
       " 'cold',\n",
       " 'clean',\n",
       " 'sanitary',\n",
       " 'wash',\n",
       " 'jaundice',\n",
       " 'yellow',\n",
       " 'hazard',\n",
       " 'inspection',\n",
       " 'violation',\n",
       " 'gloves',\n",
       " 'hairnet',\n",
       " 'nails',\n",
       " 'jewelry',\n",
       " 'sneeze',\n",
       " 'cough',\n",
       " 'runny',\n",
       " 'illegal',\n",
       " 'rotten',\n",
       " 'dirty',\n",
       " 'mouse',\n",
       " 'cockroach',\n",
       " 'contaminated',\n",
       " 'gross',\n",
       " 'disgusting',\n",
       " 'stink',\n",
       " 'old',\n",
       " 'parasite',\n",
       " 'reheat',\n",
       " 'frozen',\n",
       " 'broken',\n",
       " 'drip',\n",
       " 'bathroom',\n",
       " 'toilet',\n",
       " 'leak',\n",
       " 'trash',\n",
       " 'dark',\n",
       " 'lights',\n",
       " 'dust',\n",
       " 'puddle',\n",
       " 'pesticide',\n",
       " 'bugs',\n",
       " 'mold',\n",
       " 'user_yelping_since_delta',\n",
       " 'restaurant_categories',\n",
       " 'restaurant_neighborhoods',\n",
       " 'user_most_recent_elite_year_delta']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1924336, 168)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759039,)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped.user_most_recent_elite_year_delta.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-2e82e1107d6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdropped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestaurant_neighborhoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/pandas/core/base.pyc\u001b[0m in \u001b[0;36mvalue_counts\u001b[0;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         result = value_counts(self, sort=sort, ascending=ascending,\n\u001b[0;32m--> 430\u001b[0;31m                               normalize=normalize, bins=bins, dropna=dropna)\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/pandas/core/algorithms.pyc\u001b[0m in \u001b[0;36mvalue_counts\u001b[0;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_count_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdropna\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.value_count_object (pandas/hashtable.c:17531)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.value_count_object (pandas/hashtable.c:17268)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "dropped.user_most_recent_elite_year_delta.value_counts(dropna=False, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = []\n",
    "for i in ['restaurant_category_1',\n",
    " 'restaurant_category_2',\n",
    " 'restaurant_category_3',\n",
    " 'restaurant_category_4',\n",
    " 'restaurant_category_5',\n",
    " 'restaurant_category_6',\n",
    " 'restaurant_category_7']:\n",
    "    cats.extend(train[i].unique().tolist())\n",
    "cats = set(cats)\n",
    "cats.remove(np.nan)\n",
    "cats = sorted(cats)\n",
    "\n",
    "def proper_array(x, backfill_size=7):\n",
    "    encoder_prep = lambda x: cats.index(x)\n",
    "    temp = map(encoder_prep, x)\n",
    "    zeros = np.zeros(backfill_size, dtype='int')\n",
    "    zeros[:len(temp)] = temp\n",
    "    return zeros\n",
    "\n",
    "t = dropped.restaurant_categories.apply(proper_array)\n",
    "\n",
    "enc = OneHotEncoder(sparse=True)\n",
    "e = enc.fit_transform(np.vstack(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = []\n",
    "for i in ['restaurant_neighborhood_1', 'restaurant_neighborhood_2', 'restaurant_neighborhood_3']:\n",
    "    cats.extend(train[i].unique().tolist())\n",
    "cats = set(cats)\n",
    "cats.remove(np.nan)\n",
    "cats = sorted(cats)\n",
    "\n",
    "t = dropped.restaurant_neighborhoods.apply(proper_array, args=(3,))\n",
    "\n",
    "enc = OneHotEncoder(sparse=True)\n",
    "e = enc.fit_transform(np.vstack(t))\n",
    "\n",
    "def proper_array(x, backfill_size=3):\n",
    "    encoder_prep = lambda x: cats.index(x)\n",
    "    temp = map(encoder_prep, x)\n",
    "    zeros = np.zeros(backfill_size, dtype='int')\n",
    "    zeros[:len(temp)] = temp\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc_label = LabelEncoder()\n",
    "# el = enc_label.fit_transform(np.vstack(t)[:,0])\n",
    "# el = enc_label.fit_transform(dropped.restaurant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_label.fit_transform(dropped.restaurant_attributes_accepts_credit_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = dropped[['score_lvl_1', 'score_lvl_2', 'score_lvl_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1923536x10881 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 1923536 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# def get_out(x):\n",
    "#     try:\n",
    "#         return x[0]\n",
    "#     except:\n",
    "#         return x\n",
    "\n",
    "# topics = ['supervisor', 'training', 'safety', 'disease', 'ill', 'sick', 'poisoning', 'hygiene', 'raw', 'undercooked', 'cold', 'clean', 'sanitary', 'wash', 'jaundice', 'yellow', 'hazard', 'inspection', 'violation', 'gloves', 'hairnet', 'nails', 'jewelry', 'sneeze', 'cough', 'runny', 'illegal', 'rotten', 'dirty', 'mouse', 'cockroach', 'contaminated', 'gross', 'disgusting', 'stink', 'old', 'parasite', 'reheat', 'frozen', 'broken', 'drip', 'bathroom', 'toilet', 'leak', 'trash', 'dark', 'lights', 'dust', 'puddle', 'pesticide', 'bugs', 'mold', ]\n",
    "# matrix = np.vstack(test.manager.apply(lambda x: x[0:2]))\n",
    "# pbar = ProgressBar(maxval=len(topics)).start()\n",
    "# for index, i in enumerate(topics):\n",
    "#     t = np.vstack(test[i].apply(lambda x: x[0:2]))\n",
    "#     matrix = np.concatenate((matrix, t), axis=1)\n",
    "#     pbar.update(index)\n",
    "# pbar.finish()\n",
    "# matrix = csr_matrix(matrix)\n",
    "# X = hstack([matrix, test[['review_delta', 'previous_inspection_delta']]])\n",
    "# y = test[['score_lvl_1', 'score_lvl_2', 'score_lvl_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix = joblib.load('pickle_jar/similarity_matrix5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bins(df, bin_size=10):\n",
    "    # time delta bins\n",
    "    tdmax = df.review_delta.max()\n",
    "    tdmin = df.review_delta.min()\n",
    "    df['review_delta_bin'] = pd.cut(df[\"review_delta\"], np.arange(tdmin, tdmax, bin_size))\n",
    "    df['review_delta_bin_codes'] = df.review_delta_bin.astype('category').cat.codes\n",
    "    tdmax = df.previous_inspection_delta.max()\n",
    "    tdmin = df.previous_inspection_delta.min()\n",
    "    df['previous_inspection_delta_bin'] = pd.cut(df[\"previous_inspection_delta\"], np.arange(tdmin-1, tdmax, bin_size))\n",
    "    df['previous_inspection_delta_bin_codes'] = df.previous_inspection_delta_bin.astype('category').cat.codes\n",
    "    return df\n",
    "df = make_bins(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4071065, 185)\n",
      "(1923536, 55)\n",
      "(1923536, 3)\n"
     ]
    }
   ],
   "source": [
    "scores = ['score_lvl_1', 'score_lvl_2', 'score_lvl_3']\n",
    "# model_features = ['review_stars', 'review_delta', 'previous_inspection_delta','review_delta_bin', 'previous_inspection_delta_bin', 'polarity', 'subjectivity', 'neg', 'pos', 'neu', 'compound']\n",
    "# model_features = ['review_stars', 'review_delta', 'previous_inspection_delta', 'polarity', 'subjectivity', 'neg', 'pos', 'neu', 'compound']\n",
    "model_features = ['review_delta', 'previous_inspection_delta']\n",
    "\n",
    "X, y = extract_features(test[model_features + topics + scores].dropna())\n",
    "\n",
    "print df.shape\n",
    "print X.shape\n",
    "print y.shape\n",
    "# review_stars doesnt exist for every observation so reducing size even further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFECV\n",
    "# rfecv = RFECV(estimator=SGDClassifier(n_jobs=-1), scoring=mean_squared_error)\n",
    "# rfecv.fit(X, y.score_lvl_1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "# X_new = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit_transform(X, y.score_lvl_1)\n",
    "\n",
    "# from sklearn.feature_selection import RFE\n",
    "# rfe = RFE(estimator=LinearRegression(), n_features_to_select=3, step=1)\n",
    "# rfe.fit(X, y.score_lvl_1)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "test = SelectFwe(f_classif).fit_transform(X, y.score_lvl_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_new = SelectKBest(f_classif, k=5).fit_transform(X, y.score_lvl_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c2b813c1f3f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_new' is not defined"
     ]
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# set classifiers to test\n",
    "estimator = LinearRegression()\n",
    "# estimator = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "# estimator = SGDClassifier(n_jobs=-1, random_state=42)\n",
    "# estimator = Perceptron(n_jobs=-1, random_state=42)  # gets some nuances\n",
    "# estimator = SGDRegressor() # gets some nuances\n",
    "# estimator = KNeighborsClassifier()\n",
    "# estimator = KNeighborsRegressor()  # gets some nuances\n",
    "# estimator = DecisionTreeClassifier()\n",
    "# estimator = DecisionTreeRegressor()\n",
    "# estimator = GaussianNB()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('low_var_removal', VarianceThreshold()),\n",
    "        ('normalizer', Normalizer()),\n",
    "#         ('normalizer', Normalizer(norm='l2')), #  for text classification and clustering\n",
    "#         ('scaler', StandardScaler()),\n",
    "#         ('scaler', StandardScaler(with_mean=False)), #  for sparse matrix\n",
    "        ('clf', estimator),\n",
    "])\n",
    "\n",
    "p1,p2,p3,ytest = raw_fit(t1, y, pipeline)\n",
    "raw_scoring(p1,p2,p3,ytest)\n",
    "\n",
    "\n",
    "print(\"{} seconds elapsed\".format(time()-t0))\n",
    "\n",
    "# first representation of manager and mold plus deltas for SGDClassifier\n",
    "# Level 1 accuracy score of 0.160254863959\n",
    "# Level 2 accuracy score of 0.693050714933\n",
    "# Level 3 accuracy score of 0.574146779681\n",
    "# Contest score of 1.52839121903\n",
    "\n",
    "# sparse matrix of just manager no-mean-false and the detla for sdg\n",
    "# Level 1 accuracy score of 0.136340572778\n",
    "# Level 2 accuracy score of 0.693059032948\n",
    "# Level 3 accuracy score of 0.574184210745\n",
    "# Contest score of 1.41908388602\n",
    "\n",
    "# first representation of all similarity vecs plus deltas for SGD\n",
    "# Level 1 accuracy score of 0.0958193660009\n",
    "# Level 2 accuracy score of 0.693059032948\n",
    "# Level 3 accuracy score of 0.574184210745\n",
    "# Contest score of 1.2018434011\n",
    "\n",
    "# first two representations of all similarity vecs plus deltas for SGD\n",
    "# Level 1 accuracy score of 0.134818376157\n",
    "# Level 2 accuracy score of 0.693059032948\n",
    "# Level 3 accuracy score of 0.574184210745\n",
    "# Contest score of 1.73133292154\n",
    "\n",
    "# first five representations of all similarity vecs plus deltas for SGD\n",
    "# Level 1 accuracy score of 0.140464228379\n",
    "# Level 2 accuracy score of 0.693059032948\n",
    "# Level 3 accuracy score of 0.574184210745\n",
    "# Contest score of 1.43479163855"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1: 0.22128560699\n",
      "level 2: 0.692799495547\n",
      "level 3: 0.573199692093\n"
     ]
    }
   ],
   "source": [
    "# baseline scores if guessing zero\n",
    "guess = 0\n",
    "for index, score in enumerate(scores):\n",
    "    print(\"level {}: {}\".format(index+1, y[score].value_counts(normalize=True)[guess]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
