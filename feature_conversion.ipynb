{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import text_processors\n",
    "from progressbar import ProgressBar\n",
    "import data_grab\n",
    "from time import time\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.externals import joblib\n",
    "from scipy.sparse import csr_matrix, hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contest_metric(numpy_array_predictions, numpy_array_actual_values):\n",
    "    return metrics.weighted_rmsle(numpy_array_predictions, numpy_array_actual_values,\n",
    "            weights=metrics.KEEPING_IT_CLEAN_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contest_scoring(X, y, pipeline):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    s1 = pipeline.fit(X_train, y_train['score_lvl_1']).predict(X_test)\n",
    "    s2 = pipeline.fit(X_train, y_train['score_lvl_2']).predict(X_test)\n",
    "    s3 = pipeline.fit(X_train, y_train['score_lvl_3']).predict(X_test)\n",
    "    results = np.dstack((s1, s2, s3))\n",
    "    score = contest_metric(np.round(results[0]), np.array(y_test))\n",
    "    print(\"Contest score of {}\".format(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def raw_scoring(p1, p2, p3, ytrue):\n",
    "    '''since cross_val_score doesn't allow you to round the results beforehand. also for pymc3 and other non-sklearn models'''\n",
    "    score1 = accuracy_score(ytrue['score_lvl_1'], np.round(p1))\n",
    "    print(\"Level 1 accuracy score of {}\".format(score1))\n",
    "    score2 = accuracy_score(ytrue['score_lvl_2'], np.round(p2))\n",
    "    print(\"Level 2 accuracy score of {}\".format(score2))\n",
    "    score3 = accuracy_score(ytrue['score_lvl_3'], np.round(p3))\n",
    "    print(\"Level 3 accuracy score of {}\".format(score3))\n",
    "    \n",
    "    results = np.dstack((p1, p2, p3))[0]\n",
    "    score = contest_metric(np.round(results), np.array(ytrue))\n",
    "    print(\"Contest score of {}\".format(score))\n",
    "    \n",
    "    rounded = np.clip(np.round(results), 0, np.inf)\n",
    "    compare = pd.concat([pd.DataFrame(np.concatenate((results, rounded), axis=1)), ytrue.reset_index(drop=True)], axis=1)\n",
    "    compare.columns = ['pred1','pred2','pred3','round1','round2','round3','true1','true2','true3']\n",
    "    compare['offset1'] = compare.round1-compare.true1\n",
    "    compare['offset2'] = compare.round2-compare.true2\n",
    "    compare['offset3'] = compare.round3-compare.true3\n",
    "        \n",
    "    return score1, score2, score3, score, compare.head(10)\n",
    "\n",
    "    \n",
    "def raw_fit(X, y, pipeline):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, random_state=42)\n",
    "    \n",
    "    p1 = pipeline.fit(xtrain, ytrain['score_lvl_1']).predict(xtest)\n",
    "    p2 = pipeline.fit(xtrain, ytrain['score_lvl_2']).predict(xtest)\n",
    "    p3 = pipeline.fit(xtrain, ytrain['score_lvl_3']).predict(xtest)\n",
    "        \n",
    "    return p1, p2, p3, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    features = df.drop(['score_lvl_1', 'score_lvl_2', 'score_lvl_3'], axis=1)\n",
    "    response = df[['score_lvl_1', 'score_lvl_2', 'score_lvl_3']].astype(np.int8)\n",
    "    \n",
    "    return features, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('pickle_jar/review_text_sentiment_hierarchical_df')\n",
    "# prep = pd.read_pickle('pickle_jar/preprocessed_review_text_hierarchical_df')\n",
    "# df = pd.concat([df, prep.preprocessed_review_text], axis=1)\n",
    "sim = pd.read_pickle('pickle_jar/similarity_vectors_df')\n",
    "# tfidf = joblib.load('pickle_jar/tfidf_preprocessed_ngram3_sublinear_1mil_hierarchical_dropna')\n",
    "# matrix = joblib.load('pickle_jar/similarity_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.previous_inspection_delta = df.previous_inspection_delta.fillna(0)\n",
    "df.previous_inspection_delta = df.previous_inspection_delta.dt.days.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (53 of 53) |#########################| Elapsed Time: 0:03:46 Time: 0:03:46\n"
     ]
    }
   ],
   "source": [
    "def get_out(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "\n",
    "topics = ['manager', 'supervisor', 'training', 'safety', 'disease', 'ill', 'sick', 'poisoning', 'hygiene', 'raw', 'undercooked', 'cold', 'clean', 'sanitary', 'wash', 'jaundice', 'yellow', 'hazard', 'inspection', 'violation', 'gloves', 'hairnet', 'nails', 'jewelry', 'sneeze', 'cough', 'runny', 'illegal', 'rotten', 'dirty', 'mouse', 'cockroach', 'contaminated', 'gross', 'disgusting', 'stink', 'old', 'parasite', 'reheat', 'frozen', 'broken', 'drip', 'bathroom', 'toilet', 'leak', 'trash', 'dark', 'lights', 'dust', 'puddle', 'pesticide', 'bugs', 'mold', ]\n",
    "pbar = ProgressBar(maxval=len(topics)).start()\n",
    "for index, i in enumerate(topics):\n",
    "    df[i] = sim[i].apply(get_out)\n",
    "    pbar.update(index)\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = pd.concat([df,sim[topics]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = data_grab.get_selects('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped = df.dropna(subset=['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "dropped['user_yelping_since_delta'] = (dropped.review_date - dropped.user_yelping_since).astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "dropped['user_most_recent_elite_year_delta'] = (dropped.review_date.dt.year - dropped.user_most_recent_elite_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/IPython/kernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from IPython.kernel.zmq import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "dropped['restaurant_categories'] = train.restaurant_categories.apply(lambda x: sorted(x))\n",
    "dropped['restaurant_neighborhoods'] = train.restaurant_neighborhoods.apply(lambda x: sorted(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/IPython/kernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from IPython.kernel.zmq import kernelapp as app\n",
      "/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/IPython/kernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/IPython/kernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "dropped.drop(['review_text', 'review_date', 'user_id', 'restaurant_full_address', 'restaurant_name',\n",
    "         'inspection_date', 'inspection_id', 'inspection_date', 'sentiment', 'vader'], axis=1, inplace=True)\n",
    "dropped.drop(['user_yelping_since', 'restaurant_attributes_by_appointment_only', 'restaurant_open', 'user_most_recent_elite_year'] , axis=1, inplace=True)\n",
    "dropped.drop(['review_year',\n",
    " 'review_month',\n",
    " 'review_day',\n",
    " 'review_dayofweek',\n",
    " 'review_quarter',\n",
    " 'review_dayofyear',\n",
    " 'inspection_dayofyear',], axis=1, inplace=True)\n",
    "# dropped.drop(['restaurant_neighborhoods', 'restaurant_categories'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/pandas/core/frame.py:2148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n",
      "/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/pandas/core/generic.py:2177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "dropped['review_stars'] = dropped.review_stars.fillna(0).astype('category')\n",
    "dropped[['user_compliments_cool', 'user_compliments_cute', 'user_compliments_funny', 'user_compliments_hot',\n",
    " 'user_compliments_list', 'user_compliments_more', 'user_compliments_note', 'user_compliments_photos', 'user_compliments_plain',\n",
    " 'user_compliments_profile', 'user_compliments_writer', 'checkin_counts']] = dropped[['user_compliments_cool', 'user_compliments_cute', 'user_compliments_funny', 'user_compliments_hot',\n",
    " 'user_compliments_list', 'user_compliments_more', 'user_compliments_note', 'user_compliments_photos', 'user_compliments_plain',\n",
    " 'user_compliments_profile', 'user_compliments_writer', 'checkin_counts']].fillna(0)\n",
    "dropped[['restaurant_attributes_ages_allowed',\n",
    "         'restaurant_attributes_alcohol', \n",
    "         'restaurant_attributes_attire', \n",
    "         'restaurant_attributes_byob_corkage', \n",
    "         'restaurant_attributes_noise_level', \n",
    "         'restaurant_attributes_smoking', \n",
    "         'restaurant_attributes_wifi']] = dropped[['restaurant_attributes_ages_allowed',\n",
    "                                                   'restaurant_attributes_alcohol', \n",
    "                                                   'restaurant_attributes_attire', \n",
    "                                                   'restaurant_attributes_byob_corkage', \n",
    "                                                   'restaurant_attributes_noise_level', \n",
    "                                                   'restaurant_attributes_smoking', \n",
    "                                                   'restaurant_attributes_wifi']].convert_objects().fillna('nan')\n",
    "dropped[['restaurant_hours_friday_close',\n",
    " 'restaurant_hours_friday_open',\n",
    " 'restaurant_hours_monday_close',\n",
    " 'restaurant_hours_monday_open',\n",
    " 'restaurant_hours_saturday_close',\n",
    " 'restaurant_hours_saturday_open',\n",
    " 'restaurant_hours_sunday_close',\n",
    " 'restaurant_hours_sunday_open',\n",
    " 'restaurant_hours_thursday_close',\n",
    " 'restaurant_hours_thursday_open',\n",
    " 'restaurant_hours_tuesday_close',\n",
    " 'restaurant_hours_tuesday_open',\n",
    " 'restaurant_hours_wednesday_close',\n",
    " 'restaurant_hours_wednesday_open']] = dropped[[ 'restaurant_hours_friday_close',\n",
    " 'restaurant_hours_friday_open',\n",
    " 'restaurant_hours_monday_close',\n",
    " 'restaurant_hours_monday_open',\n",
    " 'restaurant_hours_saturday_close',\n",
    " 'restaurant_hours_saturday_open',\n",
    " 'restaurant_hours_sunday_close',\n",
    " 'restaurant_hours_sunday_open',\n",
    " 'restaurant_hours_thursday_close',\n",
    " 'restaurant_hours_thursday_open',\n",
    " 'restaurant_hours_tuesday_close',\n",
    " 'restaurant_hours_tuesday_open',\n",
    " 'restaurant_hours_wednesday_close',\n",
    " 'restaurant_hours_wednesday_open']].convert_objects().fillna('nan')\n",
    "dropped[['restaurant_ambience',\n",
    "         'restaurant_music',\n",
    "         'restaurant_parking',\n",
    "         'restaurant_zipcode']] = dropped[['restaurant_ambience',\n",
    "                                            'restaurant_music',\n",
    "                                            'restaurant_parking',\n",
    "                                            'restaurant_zipcode']].convert_objects().fillna('nan')\n",
    "dropped.user_most_recent_elite_year_delta = dropped.user_most_recent_elite_year_delta.fillna(dropped.user_most_recent_elite_year_delta.median())\n",
    "dropped.restaurant_attributes_price_range = dropped.restaurant_attributes_price_range.fillna(dropped.restaurant_attributes_price_range.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped[['manager', 'supervisor', 'training', 'safety', 'disease', 'ill', 'sick', 'poisoning', 'hygiene', 'raw', \n",
    "         'undercooked', 'cold', 'clean', 'sanitary', 'wash', 'jaundice', 'yellow', 'hazard', 'inspection', \n",
    "         'violation', 'gloves', 'hairnet', 'nails', 'jewelry', 'sneeze', 'cough', 'runny', 'illegal', 'rotten', \n",
    "         'dirty', 'mouse', 'cockroach', 'contaminated', 'gross', 'disgusting', 'stink', 'old', 'parasite', 'reheat', \n",
    "         'frozen', 'broken', 'drip', 'bathroom', 'toilet', 'leak', 'trash', 'dark', 'lights', 'dust', 'puddle', \n",
    "         'pesticide', 'bugs', 'mold']] = dropped[['manager', 'supervisor', 'training', 'safety', 'disease', 'ill', \n",
    "                                                  'sick', 'poisoning', 'hygiene', 'raw', 'undercooked', 'cold', \n",
    "                                                  'clean', 'sanitary', 'wash', 'jaundice', 'yellow', 'hazard', \n",
    "                                                  'inspection', 'violation', 'gloves', 'hairnet', 'nails', 'jewelry',\n",
    "                                                  'sneeze', 'cough', 'runny', 'illegal', 'rotten', 'dirty', 'mouse', \n",
    "                                                  'cockroach', 'contaminated', 'gross', 'disgusting', 'stink', 'old',\n",
    "                                                  'parasite', 'reheat', 'frozen', 'broken', 'drip', 'bathroom', \n",
    "                                                  'toilet', 'leak', 'trash', 'dark', 'lights', 'dust', 'puddle', \n",
    "                                                  'pesticide', 'bugs', 'mold']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped = pd.read_pickle('pickle_jar/final_dropped')\n",
    "# dropped.to_pickle('pickle_jar/final_dropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1925254, 177)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759039,)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped.user_most_recent_elite_year_delta.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3     1284912\n",
       "-2      143340\n",
       "-1      136361\n",
       "-4       98223\n",
       "-5       74546\n",
       "-6       56323\n",
       " 0       53969\n",
       "-7       40708\n",
       "-8       13722\n",
       " 1        9392\n",
       "-9        7155\n",
       " 2        3224\n",
       " 3        1631\n",
       "-10        953\n",
       " 4         541\n",
       " 5         149\n",
       " 6          51\n",
       "-11         32\n",
       " 7          22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped.user_most_recent_elite_year_delta.value_counts(dropna=False, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = []\n",
    "for i in ['restaurant_category_1',\n",
    " 'restaurant_category_2',\n",
    " 'restaurant_category_3',\n",
    " 'restaurant_category_4',\n",
    " 'restaurant_category_5',\n",
    " 'restaurant_category_6',\n",
    " 'restaurant_category_7']:\n",
    "    cats.extend(train[i].unique().tolist())\n",
    "cats = set(cats)\n",
    "cats.remove(np.nan)\n",
    "cats = sorted(cats)\n",
    "\n",
    "def proper_array(x, backfill_size=7):\n",
    "    encoder_prep = lambda x: cats.index(x)\n",
    "    temp = map(encoder_prep, x)\n",
    "    zeros = np.zeros(backfill_size, dtype='int')\n",
    "    zeros[:len(temp)] = temp\n",
    "    return zeros\n",
    "\n",
    "t = dropped.restaurant_categories.apply(proper_array)\n",
    "\n",
    "enc = OneHotEncoder(sparse=True)\n",
    "e = enc.fit_transform(np.vstack(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = []\n",
    "for i in ['restaurant_neighborhood_1', 'restaurant_neighborhood_2', 'restaurant_neighborhood_3']:\n",
    "    cats.extend(train[i].unique().tolist())\n",
    "cats = set(cats)\n",
    "cats.remove(np.nan)\n",
    "cats = sorted(cats)\n",
    "\n",
    "t = dropped.restaurant_neighborhoods.apply(proper_array, args=(3,))\n",
    "\n",
    "enc = OneHotEncoder(sparse=True)\n",
    "e = enc.fit_transform(np.vstack(t))\n",
    "\n",
    "def proper_array(x, backfill_size=3):\n",
    "    encoder_prep = lambda x: cats.index(x)\n",
    "    temp = map(encoder_prep, x)\n",
    "    zeros = np.zeros(backfill_size, dtype='int')\n",
    "    zeros[:len(temp)] = temp\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc_label = LabelEncoder()\n",
    "# el = enc_label.fit_transform(np.vstack(t)[:,0])\n",
    "# el = enc_label.fit_transform(dropped.restaurant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_label.fit_transform(dropped.restaurant_attributes_accepts_credit_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelBinarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-08f32275db96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestaurant_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LabelBinarizer' is not defined"
     ]
    }
   ],
   "source": [
    "def add_categorical_to_matrix(matrix, df, columns):\n",
    "    lb = LabelBinarizer(sparse_output=True)\n",
    "    for i in columns:\n",
    "        binarized = lb.fit_transform(df[i])\n",
    "        matrix = hstack([matrix, binarized])\n",
    "    return matrix\n",
    "\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "m = lb.fit_transform(dropped.restaurant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dropped.restauarant_stars = dropped.restaurant_stars.astype('category')\n",
    "dropped.restaurant_stars = dropped.restaurant_stars.apply(lambda x: float(x))\n",
    "\n",
    "\n",
    "# add_categorical_to_matrix(m, dropped, ['restaurant_stars'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1925254x14 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 1925254 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped.restaurant_stars.dtypes\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "test = train.dropna(subset=['review_text']).restaurant_stars\n",
    "lb.fit_transform(np.array(test, dtype='|S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1925254, 82)\n",
      "(1925254, 95)\n"
     ]
    }
   ],
   "source": [
    "temp = pd.DataFrame(dropped.restaurant_categories.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (95 of 95) |#########################| Elapsed Time: 0:02:32 Time: 0:02:32\n",
      "100% (87 of 87) |#########################| Elapsed Time: 0:01:38 Time: 0:01:38\n",
      "100% (46 of 46) |#########################| Elapsed Time: 0:00:20 Time: 0:00:20\n",
      "100% (29 of 29) |#########################| Elapsed Time: 0:00:23 Time: 0:00:23\n",
      "100% (15 of 15) |#########################| Elapsed Time: 0:00:00 Time: 0:00:00\n",
      "100% (6 of 6) |###########################| Elapsed Time: 0:00:00 Time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "# need to do it like this because pd.merge causes a memory overload\n",
    "['restaurant_category_1',\n",
    " 'restaurant_category_2',\n",
    " 'restaurant_category_3',\n",
    " 'restaurant_category_4',\n",
    " 'restaurant_category_5',\n",
    " 'restaurant_category_6',\n",
    " 'restaurant_category_7']:\n",
    "t0 = pd.get_dummies(temp[0])\n",
    "for i in range(1, 7):\n",
    "    new_dummies = pd.get_dummies(temp[i])\n",
    "    pbar = ProgressBar(maxval=len(new_dummies.columns)).start()\n",
    "    for index, column in enumerate(new_dummies.columns):\n",
    "        if column not in t0.columns:\n",
    "            t0 = pd.concat([t0, new_dummies[column]], axis=1)\n",
    "        else:\n",
    "            t0[column] = t0[column] + new_dummies[column]\n",
    "        pbar.update(index)\n",
    "    pbar.finish()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1925254, 158)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1925254x158 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 6416483 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_matrix(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = dropped[['score_lvl_1', 'score_lvl_2', 'score_lvl_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1923536x10881 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 1923536 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix = joblib.load('pickle_jar/similarity_matrix5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bins(df, bin_size=10):\n",
    "    # time delta bins\n",
    "    tdmax = df.review_delta.max()\n",
    "    tdmin = df.review_delta.min()\n",
    "    df['review_delta_bin'] = pd.cut(df[\"review_delta\"], np.arange(tdmin, tdmax, bin_size))\n",
    "    df['review_delta_bin_codes'] = df.review_delta_bin.astype('category').cat.codes\n",
    "    tdmax = df.previous_inspection_delta.max()\n",
    "    tdmin = df.previous_inspection_delta.min()\n",
    "    df['previous_inspection_delta_bin'] = pd.cut(df[\"previous_inspection_delta\"], np.arange(tdmin-1, tdmax, bin_size))\n",
    "    df['previous_inspection_delta_bin_codes'] = df.previous_inspection_delta_bin.astype('category').cat.codes\n",
    "    return df\n",
    "df = make_bins(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4071065, 185)\n",
      "(1923536, 55)\n",
      "(1923536, 3)\n"
     ]
    }
   ],
   "source": [
    "scores = ['score_lvl_1', 'score_lvl_2', 'score_lvl_3']\n",
    "# model_features = ['review_stars', 'review_delta', 'previous_inspection_delta','review_delta_bin', 'previous_inspection_delta_bin', 'polarity', 'subjectivity', 'neg', 'pos', 'neu', 'compound']\n",
    "# model_features = ['review_stars', 'review_delta', 'previous_inspection_delta', 'polarity', 'subjectivity', 'neg', 'pos', 'neu', 'compound']\n",
    "model_features = ['review_delta', 'previous_inspection_delta']\n",
    "\n",
    "X, y = extract_features(test[model_features + topics + scores].dropna())\n",
    "\n",
    "print df.shape\n",
    "print X.shape\n",
    "print y.shape\n",
    "# review_stars doesnt exist for every observation so reducing size even further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = ['restaurant_attributes_accepts_credit_cards', 'restaurant_attributes_byob', 'restaurant_attributes_caters', 'restaurant_attributes_coat_check', 'restaurant_attributes_corkage', 'restaurant_attributes_delivery', 'restaurant_attributes_dietary_restrictions_dairy_free', 'restaurant_attributes_dietary_restrictions_gluten_free', 'restaurant_attributes_dietary_restrictions_halal', 'restaurant_attributes_dietary_restrictions_kosher', 'restaurant_attributes_dietary_restrictions_soy_free', 'restaurant_attributes_dietary_restrictions_vegan', 'restaurant_attributes_dietary_restrictions_vegetarian', 'restaurant_attributes_dogs_allowed', 'restaurant_attributes_drive_thr', 'restaurant_attributes_good_for_dancing', 'restaurant_attributes_good_for_groups', 'restaurant_attributes_good_for_breakfast', 'restaurant_attributes_good_for_brunch', 'restaurant_attributes_good_for_dessert', 'restaurant_attributes_good_for_dinner', 'restaurant_attributes_good_for_latenight', 'restaurant_attributes_good_for_lunch', 'restaurant_attributes_good_for_kids', 'restaurant_attributes_happy_hour', 'restaurant_attributes_has_tv', 'restaurant_attributes_open_24_hours', 'restaurant_attributes_order_at_counter', 'restaurant_attributes_outdoor_seating',  'restaurant_attributes_payment_types_amex', 'restaurant_attributes_payment_types_cash_only', 'restaurant_attributes_payment_types_discover', 'restaurant_attributes_payment_types_mastercard', 'restaurant_attributes_payment_types_visa', 'restaurant_attributes_take_out',  'restaurant_attributes_takes_reservations', 'restaurant_attributes_waiter_service', 'restaurant_attributes_wheelchair_accessible', ]\n",
    "\n",
    "# from sklearn.feature_selection import RFECV\n",
    "# rfecv = RFECV(estimator=SGDClassifier(n_jobs=-1), scoring=mean_squared_error)\n",
    "# rfecv.fit(X, y.score_lvl_1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "# X_new = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit_transform(X, y.score_lvl_1)\n",
    "\n",
    "# from sklearn.feature_selection import RFE\n",
    "# rfe = RFE(estimator=LinearRegression(), n_features_to_select=3, step=1)\n",
    "# rfe.fit(X, y.score_lvl_1)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "# test = SelectFwe(f_classif).fit_transform(X, y.score_lvl_1)\n",
    "\n",
    "X_new = SelectKBest(f_classif, k=5).fit_transform(X, y.score_lvl_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix = joblib.load('pickle_jar/final_matrix')\n",
    "y = joblib.load('pickle_jar/final_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: Huntington Ave",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6701fa815012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'review_stars'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_stars'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_attributes_ages_allowed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_attributes_alcohol'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_attributes_attire'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_attributes_byob_corkage'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_attributes_noise_level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_attributes_smoking'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_attributes_wifi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_city'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'restaurant_hours_friday_close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_friday_open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_monday_close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_monday_open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_saturday_close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_saturday_open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_sunday_close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_sunday_open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_thursday_close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_thursday_open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_tuesday_close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_tuesday_open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_wednesday_close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_hours_wednesday_open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_ambience'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_music'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_parking'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_street'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restaurant_zipcode'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'inspection_year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inspection_month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inspection_day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inspection_dayofweek'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inspection_quarter'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/sklearn/linear_model/randomized_l1.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric)\u001b[0m\n\u001b[1;32m    442\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    443\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     ensure_min_features)\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: Huntington Ave"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RandomizedLogisticRegression\n",
    "test = ['review_stars', 'user_name', 'restaurant_stars', 'restaurant_attributes_ages_allowed', 'restaurant_attributes_alcohol', 'restaurant_attributes_attire', 'restaurant_attributes_byob_corkage', 'restaurant_attributes_noise_level', 'restaurant_attributes_smoking', 'restaurant_attributes_wifi', 'restaurant_city',  'restaurant_hours_friday_close', 'restaurant_hours_friday_open', 'restaurant_hours_monday_close', 'restaurant_hours_monday_open', 'restaurant_hours_saturday_close', 'restaurant_hours_saturday_open', 'restaurant_hours_sunday_close', 'restaurant_hours_sunday_open', 'restaurant_hours_thursday_close', 'restaurant_hours_thursday_open', 'restaurant_hours_tuesday_close', 'restaurant_hours_tuesday_open', 'restaurant_hours_wednesday_close', 'restaurant_hours_wednesday_open', 'restaurant_ambience', 'restaurant_music', 'restaurant_parking', 'restaurant_street', 'restaurant_zipcode',  'inspection_year', 'inspection_month', 'inspection_day', 'inspection_dayofweek', 'inspection_quarter',]\n",
    "rlr = RandomizedLogisticRegression()\n",
    "rlr.fit_transform(dropped[test], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1925254x14170 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 298242155 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VarianceThreshold().fit_transform(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1925254x14175 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 300167409 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = joblib.load( 'pickle_jar/tfidf_preprocessed_ngram3_sublinear_1mil_hierarchical_dropna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = joblib.load('pickle_jar/final_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1925254, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1924542, 1000000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep = pd.read_pickle('pickle_jar/preprocessed_review_text_hierarchical_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          this pretty typical cafe the sandwich wrap goo...\n",
       "1          i agree reviewer pretty typical financial dist...\n",
       "2          decent enough food overprice just large soup a...\n",
       "3          the muffin blueberry i never good blueberry su...\n",
       "4          well well well look review restaurant lobby re...\n",
       "5                                                           \n",
       "6          this place i like go deli sandwich financial d...\n",
       "7          delicato great place lunch go downtown crossin...\n",
       "8          delicato surprisingly tasty place locate alley...\n",
       "9          did ever notice matter get lunch downtown cost...\n",
       "10         i think i eat every day solid six month last y...\n",
       "11         whoa this place good monday friday morning mak...\n",
       "12         this easily one favorite place get breakfast t...\n",
       "13         everyday i love place the lady office i take g...\n",
       "14         this beat path spot place find i would rate hi...\n",
       "15         five star as i sit update review delicato i mu...\n",
       "16         i always walk past place way viga lunch i fina...\n",
       "17         delicato become regular lunch rotation i ve ti...\n",
       "18         just eat first time right office it convenient...\n",
       "19               this great sandwich shop next old city hall\n",
       "20         above average deli good bread good veggie medi...\n",
       "21         consider cheers breakfast joint i go recent fr...\n",
       "22         i love delicato cafe whether frenchman breakfa...\n",
       "23         i eat quite often office block away the food g...\n",
       "24         delicato far favorite lunch spot area believe ...\n",
       "25         i breakfast couple ham egg cheese sandwich pre...\n",
       "26         well i one experience i wait long line get chi...\n",
       "27         delicato one premier spot boston why ask quali...\n",
       "28         two reason i love delicato breakfast lunch bre...\n",
       "29         super tasty fast we try cowgirl melt pilgrim s...\n",
       "                                 ...                        \n",
       "4071035                                                     \n",
       "4071036                                                     \n",
       "4071037                                                     \n",
       "4071038                                                     \n",
       "4071039                                                     \n",
       "4071040                                                     \n",
       "4071041                                                     \n",
       "4071042                                                     \n",
       "4071043                                                     \n",
       "4071044                                                     \n",
       "4071045                                                     \n",
       "4071046                                                     \n",
       "4071047                                                     \n",
       "4071048                                                     \n",
       "4071049                                                     \n",
       "4071050                                                     \n",
       "4071051                                                     \n",
       "4071052                                                     \n",
       "4071053                                                     \n",
       "4071054                                                     \n",
       "4071055                                                     \n",
       "4071056                                                     \n",
       "4071057                                      tryin beef gyro\n",
       "4071058            awesome gyro fresh surprisingly good pita\n",
       "4071059                                                check\n",
       "4071060                                                     \n",
       "4071061                                                     \n",
       "4071062                                                     \n",
       "4071063                                                     \n",
       "4071064    great spanikopita wonderful dolmades very nice...\n",
       "Name: preprocessed_review_text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.preprocessed_review_text.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception KeyboardInterrupt in 'zmq.backend.cython.message.Frame.__dealloc__' ignored\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-62c100ac6c6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m ])\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mraw_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9b1968660772>\u001b[0m in \u001b[0;36mraw_fit\u001b[0;34m(X, y, pipeline)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_lvl_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_lvl_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_lvl_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m    140\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, n_jobs)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_lsqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/scipy/sparse/linalg/isolve/lsqr.pyc\u001b[0m in \u001b[0;36mlsqr\u001b[0;34m(A, b, damp, atol, btol, conlim, iter_lim, show, calc_var)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0manorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manorm\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malfa\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdamp\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0malfa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0malfa\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/scipy/sparse/linalg/interface.pyc\u001b[0m in \u001b[0;36mrmatvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_conj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_conj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_conj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36mdot\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;31m# Fast path for the most common case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/anaconda/envs/datasci/lib/python2.7/site-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36m_mul_vector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# csr_matvec or csc_matvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matvec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# set classifiers to test\n",
    "estimator = LinearRegression()\n",
    "# estimator = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "# estimator = SGDClassifier(n_jobs=-1, random_state=42)\n",
    "# estimator = Perceptron(n_jobs=-1, random_state=42)  # gets some nuances\n",
    "# estimator = SGDRegressor() # gets some nuances\n",
    "# estimator = KNeighborsClassifier()\n",
    "# estimator = KNeighborsRegressor()  # gets some nuances\n",
    "# estimator = DecisionTreeClassifier()\n",
    "# estimator = DecisionTreeRegressor()\n",
    "# estimator = GaussianNB()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "#         ('low_var_removal', VarianceThreshold()),\n",
    "#         ('normalizer', Normalizer()),\n",
    "#         ('normalizer', Normalizer(norm='l2')), #  for text classification and clustering\n",
    "#         ('scaler', StandardScaler()),\n",
    "#         ('scaler', StandardScaler(with_mean=False)), #  for sparse matrix\n",
    "        ('clf', estimator),\n",
    "])\n",
    "\n",
    "p1,p2,p3,ytest = raw_fit(matrix, y, pipeline)\n",
    "raw_scoring(p1,p2,p3,ytest)\n",
    "\n",
    "\n",
    "print(\"{} seconds elapsed\".format(time()-t0))\n",
    "\n",
    "# first representation of manager and mold plus deltas for SGDClassifier\n",
    "# Level 1 accuracy score of 0.160254863959\n",
    "# Level 2 accuracy score of 0.693050714933\n",
    "# Level 3 accuracy score of 0.574146779681\n",
    "# Contest score of 1.52839121903\n",
    "\n",
    "# sparse matrix of just manager no-mean-false and the detla for sdg\n",
    "# Level 1 accuracy score of 0.136340572778\n",
    "# Level 2 accuracy score of 0.693059032948\n",
    "# Level 3 accuracy score of 0.574184210745\n",
    "# Contest score of 1.41908388602\n",
    "\n",
    "# first representation of all similarity vecs plus deltas for SGD\n",
    "# Level 1 accuracy score of 0.0958193660009\n",
    "# Level 2 accuracy score of 0.693059032948\n",
    "# Level 3 accuracy score of 0.574184210745\n",
    "# Contest score of 1.2018434011\n",
    "\n",
    "# first two representations of all similarity vecs plus deltas for SGD\n",
    "# Level 1 accuracy score of 0.134818376157\n",
    "# Level 2 accuracy score of 0.693059032948\n",
    "# Level 3 accuracy score of 0.574184210745\n",
    "# Contest score of 1.73133292154\n",
    "\n",
    "# first five representations of all similarity vecs plus deltas for SGD\n",
    "# Level 1 accuracy score of 0.140464228379\n",
    "# Level 2 accuracy score of 0.693059032948\n",
    "# Level 3 accuracy score of 0.574184210745\n",
    "# Contest score of 1.43479163855"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1: 0.22128560699\n",
      "level 2: 0.692799495547\n",
      "level 3: 0.573199692093\n"
     ]
    }
   ],
   "source": [
    "# baseline scores if guessing zero\n",
    "guess = 0\n",
    "for index, score in enumerate(scores):\n",
    "    print(\"level {}: {}\".format(index+1, y[score].value_counts(normalize=True)[guess]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
